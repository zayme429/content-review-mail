#!/usr/bin/env python3
"""
é«˜çº§å†…å®¹ç®¡ç†Pipeline v2.0
æ”¯æŒï¼šå¤šå€™é€‰ç”Ÿæˆã€ç³»ç»ŸåŒ–å®¡æ ¸ã€åé¦ˆå›ºåŒ–ã€åå¥½å­¦ä¹ 
"""

import os
import sys
import json
import logging
import subprocess
from datetime import datetime
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent / 'src'))

from fetcher.rss_collector import RSSCollector
from generator.content_generator import ContentGenerator
from generator.multi_candidate import MultiCandidateGenerator
from database.content_db import ContentDatabase
from feedback.solidifier import FeedbackSolidifier
from notification.email_notifier import EmailNotifier
from notification.review_mail_sender import ReviewMailSender

# å¯¼å…¥é‚®ä»¶å®¡æ ¸ skill
sys.path.insert(0, str(Path.home() / '.openclaw' / 'workspace' / 'skills' / 'content-review-mail' / 'scripts'))
from content_review_mail import ContentReviewMail

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/root/.openclaw/workspace/content-pipeline/logs/pipeline.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class AdvancedContentPipeline:
    """é«˜çº§å†…å®¹ç®¡ç†Pipeline"""
    
    def __init__(self):
        self.base_dir = Path('/root/.openclaw/workspace/content-pipeline')
        
        # åŠ è½½é…ç½®
        self.config = self._load_json('config/pipeline.json')
        self.system_config = self._load_json('config/content_system.json')
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.collector = RSSCollector()
        self.multi_generator = MultiCandidateGenerator()
        self.db = ContentDatabase()
        self.solidifier = FeedbackSolidifier()
        self.email = EmailNotifier()
        self.review_mail = ContentReviewMail()
        
    def _load_json(self, path):
        """åŠ è½½JSONé…ç½®"""
        full_path = self.base_dir / path
        if full_path.exists():
            with open(full_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    
    def run_multi_candidate_workflow(self, count=3):
        """è¿è¡Œå¤šå€™é€‰å·¥ä½œæµ"""
        logger.info("ğŸš€ å¯åŠ¨å¤šå€™é€‰å†…å®¹ç”Ÿæˆå·¥ä½œæµ")
        
        today = datetime.now().strftime('%Y%m%d')
        
        try:
            # æ­¥éª¤1: é‡‡é›†çƒ­ç‚¹
            logger.info("=== æ­¥éª¤1: é‡‡é›†çƒ­ç‚¹èµ„è®¯ ===")
            news_items = self.collector.collect_all()
            if not news_items:
                logger.error("æœªé‡‡é›†åˆ°èµ„è®¯ï¼Œç»ˆæ­¢")
                return False
            
            scored_items = self.collector.score_items(news_items)
            top_items = scored_items[:10]
            
            # æ­¥éª¤2: è·å–å†å²ä¸»é¢˜ï¼ˆç”¨äºå»é‡ï¼‰
            recent_topics = [a['topic'] for a in self.db.get_article_history(limit=20)]
            
            # æ­¥éª¤3: ç”Ÿæˆå¤šå€™é€‰
            logger.info(f"=== æ­¥éª¤2: ç”Ÿæˆ {count} ä¸ªå€™é€‰ ===")
            candidates = self.multi_generator.generate_candidates(
                top_items, recent_topics, count=count
            )
            
            if not candidates:
                logger.error("å€™é€‰ç”Ÿæˆå¤±è´¥")
                return False
            
            # æ­¥éª¤4: ä¿å­˜åˆ°æ•°æ®åº“
            logger.info("=== æ­¥éª¤3: ä¿å­˜å€™é€‰åˆ°æ•°æ®åº“ ===")
            
            # é€‰æ‹©æœ€é«˜åˆ†å€™é€‰ä½œä¸ºä¸»æ–‡ç« 
            best_candidate = max(candidates, key=lambda x: x['quality_score'] + x['uniqueness_score'])
            
            article_id = self.db.save_article(
                date=today,
                topic=best_candidate['topic'],
                content=best_candidate['content'],
                candidates=candidates,
                status='pending_review'
            )
            
            logger.info(f"âœ… æ–‡ç« å·²ä¿å­˜ï¼ŒID: {article_id}")
            
            # æ­¥éª¤5: å‘é€å®¡æ ¸é‚®ä»¶
            logger.info("=== æ­¥éª¤4: å‘é€å®¡æ ¸é‚®ä»¶ ===")
            
            # ä¿å­˜å€™é€‰æ–‡ä»¶ä¾›æŸ¥çœ‹
            self._save_candidates_for_review(today, candidates)
            
            # æ­¥éª¤5: å‘é€å®¡æ ¸é‚®ä»¶ï¼ˆä½¿ç”¨ä¼˜åŒ–ç‰ˆHTMLé‚®ä»¶å‘é€å™¨ï¼‰
            logger.info("=== æ­¥éª¤4: å‘é€å®¡æ ¸é‚®ä»¶ï¼ˆHTMLå®Œæ•´ç‰ˆï¼‰ ===")
            
            # è¯»å–å®Œæ•´æ–‡ç« å†…å®¹
            candidates_with_content = []
            for i, c in enumerate(candidates, 1):
                candidate_file = self.base_dir / 'output' / today / f'candidate_{i}.md'
                if candidate_file.exists():
                    with open(candidate_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        # æå–æ­£æ–‡ï¼ˆå»æ‰frontmatterï¼‰
                        body_start = content.find('---', content.find('---') + 3) + 3
                        full_content = content[body_start:].strip()
                        c['content'] = full_content
                candidates_with_content.append(c)
            
            # ä½¿ç”¨æ–°çš„HTMLé‚®ä»¶å‘é€å™¨
            smtp_config = {
                'host': 'smtp.163.com',
                'port': 465,
                'user': '13257667003@163.com',
                'pass': 'XUnhjmQwxUa7pKFt',
                'from': '13257667003@163.com'
            }
            mail_sender = ReviewMailSender(smtp_config)
            email_sent = mail_sender.send_html_review_email(
                to='ZaymeShaw199742@outlook.com',
                candidates=candidates_with_content,
                article_date=today
            )
            
            if email_sent:
                logger.info("âœ… HTMLå®¡æ ¸é‚®ä»¶å·²å‘é€ï¼ˆå®Œæ•´æ–‡ç« +ä¼˜åŒ–æ’ç‰ˆï¼‰")
            else:
                logger.warning("âš ï¸ é‚®ä»¶å‘é€å¤±è´¥ï¼Œè¾“å‡ºåˆ°æ§åˆ¶å°")
                self._output_console_notification(candidates, today)

            # æ­¥éª¤5: æ¨é€è¯„åˆ†æœ€é«˜çš„å€™é€‰åˆ°å¾®ä¿¡è‰ç¨¿ç®±
            logger.info("=== æ­¥éª¤5: æ¨é€ä¸»æ¨å€™é€‰åˆ°è‰ç¨¿ç®± ===")
            best_idx = candidates.index(best_candidate) + 1
            pushed = self._publish_candidate(today, best_idx)
            if pushed:
                logger.info(f"âœ… å€™é€‰ {best_idx}ã€Œ{best_candidate['topic']}ã€å·²æ¨é€åˆ°è‰ç¨¿ç®±")
            else:
                logger.warning("âš ï¸ è‰ç¨¿ç®±æ¨é€å¤±è´¥ï¼Œå¯æ‰‹åŠ¨æ‰§è¡Œï¼špython3 pipeline_v2.py --select {today} --candidate {best_idx}")
            
            logger.info("âœ… å¤šå€™é€‰å·¥ä½œæµå®Œæˆï¼Œç­‰å¾…å®¡æ ¸")
            return True
            
        except Exception as e:
            logger.error(f"âŒ å·¥ä½œæµå¤±è´¥: {e}", exc_info=True)
            return False
    
    def _save_candidates_for_review(self, date: str, candidates: list):
        """ä¿å­˜å€™é€‰ä¾›å®¡æ ¸"""
        output_dir = self.base_dir / 'output' / date
        output_dir.mkdir(exist_ok=True)
        
        for i, c in enumerate(candidates, 1):
            file_path = output_dir / f'candidate_{i}.md'
            with open(file_path, 'w', encoding='utf-8') as f:
                # YAML frontmatter - é¿å…ç‰¹æ®Šå­—ç¬¦å¯¼è‡´è§£æé”™è¯¯
                title = c['topic'].replace('"', '').replace("'", '')
                angle = c.get('angle', '').replace('"', '').replace("'", '')
                angle_type = c.get('angle_type', '').replace('"', '').replace("'", '')
                # é»˜è®¤å°é¢ï¼ˆå¾®ä¿¡å…¬ä¼—å·è¦æ±‚å¿…é¡»æœ‰å°é¢ï¼‰
                cover = c.get('cover', 'https://images.unsplash.com/photo-1677442135703-1787eea5ce01?w=900')
                f.write(f"---\n")
                f.write(f"title: {title}\n")
                f.write(f"angle: {angle}\n")
                f.write(f"type: {angle_type}\n")
                f.write(f"quality_score: {c['quality_score']}\n")
                f.write(f"uniqueness_score: {c['uniqueness_score']}\n")
                f.write(f"cover: {cover}\n")
                f.write(f"---\n\n")
                f.write(c['content'])
        
        logger.info(f"âœ… å€™é€‰å·²ä¿å­˜åˆ°: {output_dir}")
    
    def _output_console_notification(self, candidates: list, date: str):
        """è¾“å‡ºåˆ°æ§åˆ¶å°ï¼ˆé‚®ä»¶å¤‡é€‰ï¼‰"""
        print("\n" + "="*70)
        print("ğŸ“„ å†…å®¹å®¡æ ¸é€šçŸ¥")
        print("="*70)
        print(f"æ—¥æœŸ: {date}")
        print(f"å€™é€‰æ•°é‡: {len(candidates)}")
        print("\nå€™é€‰åˆ—è¡¨:")
        
        for i, c in enumerate(candidates, 1):
            print(f"\nå€™é€‰ {i}: {c['topic']}")
            print(f"  è§’åº¦: {c['angle_type']}")
            print(f"  è´¨é‡åˆ†: {c['quality_score']:.1f} | ç‹¬ç‰¹åˆ†: {c['uniqueness_score']:.1f}")
            print(f"  å­—æ•°: {c['word_count']}")
        
        print("\nå®¡æ ¸æ“ä½œ:")
        print(f"  1. æŸ¥çœ‹å€™é€‰: /output/{date}/candidate_[1-3].md")
        print(f"  2. é€‰æ‹©å‘å¸ƒ: python pipeline.py --select {date} --candidate [1-3]")
        print(f"  3. é‡æ–°ç”Ÿæˆ: python pipeline.py --regenerate {date} --direction '[æ–¹å‘]'")
        print(f"  4. æŸ¥çœ‹åé¦ˆæŒ‡å—: cat REVIEW_GUIDE.md")
        print("="*70 + "\n")
    
    def process_review(self, date: str, action: str, **kwargs):
        """å¤„ç†å®¡æ ¸"""
        logger.info(f"å¤„ç†å®¡æ ¸: {date}, åŠ¨ä½œ: {action}")
        
        if action == 'select':
            # é€‰æ‹©å€™é€‰å‘å¸ƒ
            candidate_num = kwargs.get('candidate_num', 1)
            return self._publish_candidate(date, candidate_num)
            
        elif action == 'regenerate':
            # é‡æ–°ç”Ÿæˆ
            direction = kwargs.get('direction', '')
            return self._regenerate_with_direction(date, direction)
            
        elif action == 'feedback':
            # è®°å½•åé¦ˆ
            feedback_type = kwargs.get('type', '')
            content = kwargs.get('content', '')
            return self._record_and_solidify_feedback(date, feedback_type, content)
            
        elif action == 'skip':
            # è·³è¿‡
            logger.info(f"è·³è¿‡ {date} çš„å‘å¸ƒ")
            return True
            
        else:
            logger.error(f"æœªçŸ¥å®¡æ ¸åŠ¨ä½œ: {action}")
            return False
    
    def _publish_candidate(self, date: str, candidate_num: int):
        """å‘å¸ƒæŒ‡å®šå€™é€‰"""
        candidate_file = self.base_dir / 'output' / date / f'candidate_{candidate_num}.md'
        
        if not candidate_file.exists():
            logger.error(f"å€™é€‰æ–‡ä»¶ä¸å­˜åœ¨: {candidate_file}")
            return False
        
        # è°ƒç”¨wechat-publisherå‘å¸ƒ
        try:
            result = subprocess.run(
                ['wenyan', 'publish', '-f', str(candidate_file), '-t', 'lapis', '-h', 'solarized-light'],
                capture_output=True,
                text=True,
                timeout=120,
                env={**os.environ, 'WECHAT_APP_ID': 'wx5c6f2e9b5734ddd5', 'WECHAT_APP_SECRET': 'baf071b9ca8e805992a26111c552b9f9'}
            )
            
            if 'ä¸Šä¼ æˆåŠŸ' in result.stdout:
                logger.info(f"âœ… å€™é€‰ {candidate_num} å·²å‘å¸ƒåˆ°è‰ç¨¿ç®±")
                return True
            else:
                logger.error(f"å‘å¸ƒå¤±è´¥: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"å‘å¸ƒå¼‚å¸¸: {e}")
            return False
    
    def _regenerate_with_direction(self, date: str, direction: str):
        """æŒ‰æ–°æ–¹å‘é‡æ–°ç”Ÿæˆ"""
        logger.info(f"æŒ‰æ–¹å‘é‡æ–°ç”Ÿæˆ: {direction}")
        
        # è®°å½•åˆ°åé¦ˆç³»ç»Ÿ
        self.solidifier.record_feedback(
            article_id=date,
            stage='é‡æ–°ç”Ÿæˆ',
            feedback_type='å†…å®¹æ–¹å‘',
            content=f'ç”¨æˆ·è¦æ±‚é‡æ–°ç”Ÿæˆï¼Œæ–¹å‘: {direction}',
            severity='medium'
        )
        
        # é‡æ–°è¿è¡Œç”Ÿæˆæµç¨‹
        return self.run_multi_candidate_workflow()
    
    def _record_and_solidify_feedback(self, date: str, feedback_type: str, content: str):
        """è®°å½•å¹¶å›ºåŒ–åé¦ˆ"""
        logger.info(f"è®°å½•åé¦ˆ: {feedback_type}")
        
        # è®°å½•åˆ°æ•°æ®åº“
        # TODO: ä»æ•°æ®åº“è·å–article_id
        
        # å›ºåŒ–åˆ°ç³»ç»Ÿ
        self.solidifier.record_feedback(
            article_id=date,
            stage='åˆç¨¿å®¡æ ¸',
            feedback_type=feedback_type,
            content=content
        )
        
        logger.info("âœ… åé¦ˆå·²è®°å½•å¹¶å›ºåŒ–")
        return True
    
    def generate_feedback_report(self, days: int = 7):
        """ç”Ÿæˆåé¦ˆæŠ¥å‘Š"""
        report = self.solidifier.generate_feedback_report(days)
        print(report)
        return report

if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='Advanced Content Pipeline')
    parser.add_argument('--run', action='store_true', help='è¿è¡Œå¤šå€™é€‰ç”Ÿæˆ')
    parser.add_argument('--select', type=str, help='é€‰æ‹©å€™é€‰å‘å¸ƒ (æ—¥æœŸ)')
    parser.add_argument('--candidate', type=int, default=1, help='å€™é€‰ç¼–å·')
    parser.add_argument('--regenerate', type=str, help='é‡æ–°ç”Ÿæˆ (æ—¥æœŸ)')
    parser.add_argument('--direction', type=str, help='é‡æ–°ç”Ÿæˆæ–¹å‘')
    parser.add_argument('--feedback', type=str, help='è®°å½•åé¦ˆ (æ—¥æœŸ)')
    parser.add_argument('--type', type=str, help='åé¦ˆç±»å‹')
    parser.add_argument('--content', type=str, help='åé¦ˆå†…å®¹')
    parser.add_argument('--report', action='store_true', help='ç”Ÿæˆåé¦ˆæŠ¥å‘Š')
    parser.add_argument('--days', type=int, default=7, help='æŠ¥å‘Šå¤©æ•°')
    parser.add_argument('--check-mail', action='store_true', help='æ£€æŸ¥é‚®ä»¶å›å¤')
    
    args = parser.parse_args()
    
    pipeline = AdvancedContentPipeline()
    
    if args.run:
        success = pipeline.run_multi_candidate_workflow(count=3)
        sys.exit(0 if success else 1)
        
    elif args.select:
        success = pipeline.process_review(
            args.select, 'select', candidate_num=args.candidate
        )
        sys.exit(0 if success else 1)
        
    elif args.regenerate:
        success = pipeline.process_review(
            args.regenerate, 'regenerate', direction=args.direction or ''
        )
        sys.exit(0 if success else 1)
        
    elif args.feedback:
        success = pipeline.process_review(
            args.feedback, 'feedback', type=args.type, content=args.content
        )
        sys.exit(0 if success else 1)
        
    elif args.report:
        pipeline.generate_feedback_report(args.days)
        
    elif args.check_mail:
        # æ£€æŸ¥é‚®ä»¶å›å¤
        logger.info("æ£€æŸ¥é‚®ä»¶å›å¤...")
        emails = pipeline.review_mail.check_new_emails()
        
        for email in emails:
            if pipeline.review_mail.is_review_reply(email):
                logger.info(f"æ”¶åˆ°å®¡æ ¸å›å¤: {email.get('subject', '')}")
                instruction = pipeline.review_mail.parse_instruction(email.get('body', ''))
                logger.info(f"è§£ææŒ‡ä»¤: {instruction}")
                
    else:
        # é»˜è®¤è¿è¡Œ
        success = pipeline.run_multi_candidate_workflow(count=3)
        sys.exit(0 if success else 1)
