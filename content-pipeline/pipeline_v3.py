#!/usr/bin/env python3
"""
å†…å®¹ç”Ÿäº§ç®¡çº¿ v3.0
æµç¨‹ï¼šä¸»é¢˜ç¡®å®š â†’ æ–‡çŒ®é‡‡é›† â†’ é€‰é¢˜è®¾è®¡ Ã— 3 â†’ æ–‡ç« ç”Ÿæˆ Ã— 3 â†’ å®¡æ ¸é‚®ä»¶
"""

import os
import sys
import json
import logging
import subprocess
from datetime import datetime
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent / 'src'))

from fetcher.rss_collector import RSSCollector
from generator.content_generator import ContentGenerator
from database.content_db import ContentDatabase
from notification.review_mail_sender import ReviewMailSender

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/root/.openclaw/workspace/content-pipeline/logs/pipeline.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

BASE_DIR = Path('/root/.openclaw/workspace/content-pipeline')
WECHAT_SEARCH = Path.home() / '.openclaw/workspace/skills/wechat-search/wechat_search.py'



def _load_secrets():
    """åŠ è½½æ•æ„Ÿé…ç½®"""
    secrets_path = Path('/root/.openclaw/workspace/content-pipeline/config/secrets.json')
    if secrets_path.exists():
        with open(secrets_path) as f:
            return json.load(f)
    raise FileNotFoundError(f"secrets.json not found: {secrets_path}\nCopy config/secrets.example.json to config/secrets.json and fill in your values.")

class ContentPipelineV3:

    def __init__(self):
        self.config = self._load_json('config/pipeline.json')
        self.secrets = _load_secrets()
        self.generator = ContentGenerator()
        self.collector = RSSCollector()
        self.db = ContentDatabase()

    def _load_json(self, path):
        full = BASE_DIR / path
        return json.load(open(full)) if full.exists() else {}

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 1: ä¸»é¢˜ç¡®å®š
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def determine_topic(self, manual_topic: str = None) -> dict:
        """ä¸‰ç§æ¨¡å¼ï¼šæ‰‹åŠ¨æŒ‡å®š / é…ç½®æ–‡ä»¶ / è‡ªåŠ¨çƒ­ç‚¹"""
        logger.info("=== Step 1: ç¡®å®šä¸»é¢˜ ===")

        if manual_topic:
            logger.info(f"æ¨¡å¼A: æ‰‹åŠ¨æŒ‡å®šä¸»é¢˜ â†’ {manual_topic}")
            return {'topic': manual_topic, 'mode': 'manual', 'keywords': [manual_topic]}

        weekly_focus = self.config.get('weekly_focus')
        if weekly_focus:
            keywords = self.config.get('search_keywords', [weekly_focus])
            logger.info(f"æ¨¡å¼B: é…ç½®æ–‡ä»¶ä¸»é¢˜ â†’ {weekly_focus}")
            return {'topic': weekly_focus, 'mode': 'config', 'keywords': keywords}

        # æ¨¡å¼C: è‡ªåŠ¨ä» RSS çƒ­ç‚¹æç‚¼ä¸»é¢˜
        logger.info("æ¨¡å¼C: è‡ªåŠ¨çƒ­ç‚¹æç‚¼ä¸»é¢˜")
        news = self.collector.collect_all()
        scored = self.collector.score_items(news)[:5]
        news_text = '\n'.join([f"- {n['title']} ({n['source']})" for n in scored])
        prompt = f"""æ ¹æ®ä»¥ä¸‹çƒ­ç‚¹æ–°é—»ï¼Œæç‚¼ä¸€ä¸ªé€‚åˆå†™æ·±åº¦æ–‡ç« çš„ä¸»é¢˜ï¼š

{news_text}

è¾“å‡ºæ ¼å¼ï¼š
ä¸»é¢˜ï¼š[ä¸»é¢˜åç§°ï¼Œ10å­—ä»¥å†…]
å…³é”®è¯ï¼š[3-5ä¸ªæœç´¢å…³é”®è¯ï¼Œé€—å·åˆ†éš”]
æ–¹å‘ï¼š[ä¸€å¥è¯è¯´æ˜å†™ä½œæ–¹å‘]"""

        result = self.generator._call_llm(prompt)
        topic = keywords = direction = ''
        for line in result.strip().split('\n'):
            if 'ä¸»é¢˜ï¼š' in line or 'ä¸»é¢˜:' in line:
                topic = line.split('ï¼š', 1)[-1].split(':', 1)[-1].strip()
            elif 'å…³é”®è¯ï¼š' in line or 'å…³é”®è¯:' in line:
                keywords = [k.strip() for k in line.split('ï¼š', 1)[-1].split(':', 1)[-1].split(',')]
            elif 'æ–¹å‘ï¼š' in line or 'æ–¹å‘:' in line:
                direction = line.split('ï¼š', 1)[-1].split(':', 1)[-1].strip()

        logger.info(f"è‡ªåŠ¨æç‚¼ä¸»é¢˜: {topic}")
        return {'topic': topic or 'äººå·¥æ™ºèƒ½åº”ç”¨', 'mode': 'auto', 'keywords': keywords or [topic], 'direction': direction}

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 2: æ–‡çŒ®é‡‡é›†
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def collect_literature(self, topic_info: dict) -> list:
        """æœç´¢å¹¶æŠ“å–æ–‡çŒ®å…¨æ–‡ - ä½¿ç”¨ Tavily Search API"""
        logger.info("=== Step 2: æ–‡çŒ®é‡‡é›† ===")
        keywords = topic_info.get('keywords', [topic_info['topic']])
        literature = []

        for kw in keywords[:3]:
            logger.info(f"æœç´¢å…³é”®è¯: {kw}")

            # å¾®ä¿¡å…¬ä¼—å·æœç´¢
            try:
                results = self._tavily_search(f"{kw} site:mp.weixin.qq.com", max_results=5)
                for r in results:
                    literature.append({
                        'title': r.get('title', ''),
                        'url': r.get('url', ''),
                        'source': 'å¾®ä¿¡å…¬ä¼—å·',
                        'summary': r.get('content', '')[:300],
                        'full_text': r.get('content', ''),
                        'search_keyword': kw
                    })
                logger.info(f"  å¾®ä¿¡æœç´¢: {len(results)} ç¯‡")
            except Exception as e:
                logger.warning(f"  å¾®ä¿¡æœç´¢å¤±è´¥: {e}")

            # é€šç”¨æœç´¢
            try:
                results = self._tavily_search(f"{kw} æ·±åº¦åˆ†æ", max_results=5)
                for r in results:
                    if 'mp.weixin.qq.com' not in r.get('url', ''):
                        literature.append({
                            'title': r.get('title', ''),
                            'url': r.get('url', ''),
                            'source': r.get('url', '').split('/')[2] if r.get('url') else 'ç½‘ç»œ',
                            'summary': r.get('content', '')[:300],
                            'full_text': r.get('content', ''),
                            'search_keyword': kw
                        })
                logger.info(f"  é€šç”¨æœç´¢: {len(results)} ç¯‡")
            except Exception as e:
                logger.warning(f"  é€šç”¨æœç´¢å¤±è´¥: {e}")

        # å»é‡
        seen = set()
        unique = []
        for item in literature:
            if item['title'] and item['title'] not in seen:
                seen.add(item['title'])
                unique.append(item)

        # å¯¹æ²¡æœ‰å…¨æ–‡çš„æ¡ç›®å°è¯•æŠ“å–
        for item in unique[:15]:
            if not item['full_text'] and item['url']:
                try:
                    item['full_text'] = self._fetch_full_text(item['url'])[:3000]
                    logger.info(f"  âœ“ æŠ“å–å…¨æ–‡: {item['title'][:40]}...")
                except Exception:
                    pass

        result = unique[:15]
        logger.info(f"âœ… æ–‡çŒ®é‡‡é›†å®Œæˆï¼Œå…± {len(result)} ç¯‡")
        return result

    def _tavily_search(self, query: str, max_results: int = 5) -> list:
        """è°ƒç”¨ Tavily Search API"""
        import urllib.request
        api_key = os.environ.get('TAVILY_API_KEY') or self.secrets.get('tavily', {}).get('api_key', '')
        data = json.dumps({
            'api_key': api_key,
            'query': query,
            'max_results': max_results,
            'include_answer': False
        }).encode()
        req = urllib.request.Request(
            'https://api.tavily.com/search',
            data=data,
            headers={'Content-Type': 'application/json'}
        )
        with urllib.request.urlopen(req, timeout=15) as r:
            result = json.loads(r.read())
        return result.get('results', [])

    def _fetch_full_text(self, url: str) -> str:
        """æŠ“å–æ–‡ç« å…¨æ–‡"""
        import urllib.request
        import html
        import re
        req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
        with urllib.request.urlopen(req, timeout=10) as resp:
            raw = resp.read().decode('utf-8', errors='ignore')
        # ç®€å•æå–æ­£æ–‡
        raw = re.sub(r'<script[^>]*>.*?</script>', '', raw, flags=re.DOTALL)
        raw = re.sub(r'<style[^>]*>.*?</style>', '', raw, flags=re.DOTALL)
        raw = re.sub(r'<[^>]+>', ' ', raw)
        raw = html.unescape(raw)
        raw = re.sub(r'\s+', ' ', raw).strip()
        return raw

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 3: é€‰é¢˜è®¾è®¡ Ã— 3
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def design_topics(self, topic_info: dict, literature: list) -> list:
        """ä¸ºæ¯ä¸ªå€™é€‰ç‹¬ç«‹è®¾è®¡é€‰é¢˜"""
        logger.info("=== Step 3: é€‰é¢˜è®¾è®¡ ===")

        # æ„å»ºæ–‡çŒ®æ‘˜è¦ä¾› LLM å‚è€ƒ
        lit_summary = ""
        for i, item in enumerate(literature, 1):
            lit_summary += f"\n[{i}] {item['title']}\næ¥æº: {item['source']} | URL: {item['url']}\næ‘˜è¦: {item['summary'][:200]}\n"

        prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±ç§‘æŠ€ä¸“æ ç¼–è¾‘ã€‚

ä¸»é¢˜ï¼š{topic_info['topic']}
å†™ä½œæ–¹å‘ï¼š{topic_info.get('direction', 'æ·±åº¦åˆ†æ+å®ç”¨å»ºè®®')}

ä»¥ä¸‹æ˜¯æ”¶é›†åˆ°çš„æ–‡çŒ®èµ„æ–™ï¼š
{lit_summary}

è¯·ä¸º3ç¯‡å€™é€‰æ–‡ç« åˆ†åˆ«è®¾è®¡é€‰é¢˜æ–¹æ¡ˆï¼Œæ¯ç¯‡é€‰é¢˜å¿…é¡»ï¼š
1. è§’åº¦ä¸åŒï¼ˆå®æˆ˜/æ·±åº¦/æ•…äº‹ ä¸‰ç§ä¹‹ä¸€ï¼‰
2. ä»ä¸Šè¿°æ–‡çŒ®ä¸­é€‰3ç¯‡æœ€ç›¸å…³çš„ä½œä¸ºå‚è€ƒï¼ˆç”¨ç¼–å·[1][2][3]ç­‰æ ‡æ³¨ï¼‰
3. é€‰é¢˜ä¹‹é—´ä¸é‡å¤

è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼æŒ‰æ­¤æ ¼å¼ï¼‰ï¼š

===å€™é€‰1===
é¢˜ç›®ï¼š[æ–‡ç« æ ‡é¢˜]
è§’åº¦ï¼šå®æˆ˜æ´¾
æ‘˜è¦ï¼š[200å­—å†™ä½œæ–¹å‘è¯´æ˜]
å‚è€ƒæ–‡çŒ®ï¼š[1][3][5]
é€‰é¢˜ç†ç”±ï¼š[ä¸ºä»€ä¹ˆé€‰è¿™ä¸ªè§’åº¦å’Œè¿™äº›æ–‡çŒ®]

===å€™é€‰2===
é¢˜ç›®ï¼š[æ–‡ç« æ ‡é¢˜]
è§’åº¦ï¼šæ·±åº¦æ´¾
æ‘˜è¦ï¼š[200å­—å†™ä½œæ–¹å‘è¯´æ˜]
å‚è€ƒæ–‡çŒ®ï¼š[2][4][6]
é€‰é¢˜ç†ç”±ï¼š[ä¸ºä»€ä¹ˆé€‰è¿™ä¸ªè§’åº¦å’Œè¿™äº›æ–‡çŒ®]

===å€™é€‰3===
é¢˜ç›®ï¼š[æ–‡ç« æ ‡é¢˜]
è§’åº¦ï¼šæ•…äº‹æ´¾
æ‘˜è¦ï¼š[200å­—å†™ä½œæ–¹å‘è¯´æ˜]
å‚è€ƒæ–‡çŒ®ï¼š[1][7][9]
é€‰é¢˜ç†ç”±ï¼š[ä¸ºä»€ä¹ˆé€‰è¿™ä¸ªè§’åº¦å’Œè¿™äº›æ–‡çŒ®]"""

        result = self.generator._call_llm(prompt)
        topics = self._parse_topic_designs(result, literature)
        logger.info(f"âœ… é€‰é¢˜è®¾è®¡å®Œæˆï¼Œå…± {len(topics)} ä¸ªå€™é€‰")
        return topics

    def _parse_topic_designs(self, result: str, literature: list) -> list:
        """è§£æé€‰é¢˜è®¾è®¡ç»“æœ"""
        topics = []
        blocks = result.split('===å€™é€‰')
        for block in blocks[1:]:
            lines = block.strip().split('\n')
            topic = {'title': '', 'angle': '', 'summary': '', 'refs': [], 'reason': ''}
            for line in lines:
                if 'é¢˜ç›®ï¼š' in line or 'é¢˜ç›®:' in line:
                    topic['title'] = line.split('ï¼š', 1)[-1].split(':', 1)[-1].strip()
                elif 'è§’åº¦ï¼š' in line or 'è§’åº¦:' in line:
                    topic['angle'] = line.split('ï¼š', 1)[-1].split(':', 1)[-1].strip()
                elif 'æ‘˜è¦ï¼š' in line or 'æ‘˜è¦:' in line:
                    topic['summary'] = line.split('ï¼š', 1)[-1].split(':', 1)[-1].strip()
                elif 'å‚è€ƒæ–‡çŒ®ï¼š' in line or 'å‚è€ƒæ–‡çŒ®:' in line:
                    import re
                    indices = [int(x)-1 for x in re.findall(r'\[(\d+)\]', line)]
                    topic['refs'] = [literature[i] for i in indices if i < len(literature)]
                elif 'é€‰é¢˜ç†ç”±ï¼š' in line or 'é€‰é¢˜ç†ç”±:' in line:
                    topic['reason'] = line.split('ï¼š', 1)[-1].split(':', 1)[-1].strip()
            if topic['title']:
                topics.append(topic)
        return topics

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 4: æ–‡ç« ç”Ÿæˆ Ã— 3
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def generate_articles(self, topic_designs: list) -> list:
        """æ ¹æ®é€‰é¢˜è®¾è®¡ç”Ÿæˆæ–‡ç« """
        logger.info("=== Step 4: æ–‡ç« ç”Ÿæˆ ===")
        candidates = []

        for i, design in enumerate(topic_designs, 1):
            logger.info(f"ç”Ÿæˆå€™é€‰ {i}: {design['title']}")

            # æ„å»ºå‚è€ƒæ–‡çŒ®å†…å®¹
            refs_text = ""
            for j, ref in enumerate(design['refs'], 1):
                refs_text += f"\nå‚è€ƒ{j}ï¼š{ref['title']}\næ¥æºï¼š{ref['source']}\nå†…å®¹ï¼š{ref.get('full_text', ref.get('summary', ''))[:1000]}\n"

            writing_rules = self.config.get('content_strategy', {}).get('writing_rules', [])
            rules_text = '\n'.join([f'{i+6}. {r}' for i, r in enumerate(writing_rules)])

            prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±ç§‘æŠ€ä¸“æ ä½œå®¶ã€‚

æ–‡ç« é¢˜ç›®ï¼š{design['title']}
å†™ä½œè§’åº¦ï¼š{design['angle']}
å†™ä½œæ–¹å‘ï¼š{design['summary']}

å‚è€ƒæ–‡çŒ®ï¼ˆè¯·åœ¨æ–‡ç« ä¸­å¼•ç”¨ï¼Œæ ¼å¼ï¼š[æ¥æºåç§°]ï¼‰ï¼š
{refs_text}

å†™ä½œè¦æ±‚ï¼š
1. 1500-2000å­—
2. ç»“æ„ï¼šå¼•è¨€â†’ç°è±¡åˆ†æâ†’æ·±åº¦æ´å¯Ÿâ†’è¡ŒåŠ¨å»ºè®®â†’ç»“è¯­
3. å¿…é¡»å¼•ç”¨å‚è€ƒæ–‡çŒ®ä¸­çš„å…·ä½“æ•°æ®æˆ–è§‚ç‚¹ï¼Œå¹¶æ ‡æ³¨æ¥æº
4. é£æ ¼ï¼š{design['angle']}ï¼Œæœ‰æ¸©åº¦ï¼Œæœ‰æ´è§
5. æ‹’ç»é™ˆè¯æ»¥è°ƒå’Œè´©å–ç„¦è™‘
{rules_text}

ç›´æ¥è¾“å‡ºæ–‡ç« æ­£æ–‡ï¼Œä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ã€‚"""

            article = self.generator._call_llm(prompt)
            quality_score = self._score_quality(article)

            candidates.append({
                'topic': design['title'],
                'angle': design['summary'],
                'angle_type': design['angle'],
                'content': article,
                'quality_score': quality_score,
                'uniqueness_score': 7.5,
                'word_count': len(article),
                # æº¯æºä¿¡æ¯
                'source_news': [{'title': r['title'], 'source': r['source'], 'url': r['url']} for r in design['refs']],
                'angle_reason': design['reason'],
                'topic_summary': design['summary'],
            })
            logger.info(f"  âœ… å€™é€‰ {i} ç”Ÿæˆå®Œæˆï¼Œè´¨é‡åˆ†: {quality_score}")

        return candidates

    def _score_quality(self, content: str) -> float:
        score = 5.0
        if 'æ¡ˆä¾‹' in content or 'ä¾‹å¦‚' in content: score += 1
        if '%' in content or 'æ•°æ®' in content: score += 1
        if 'å»ºè®®' in content or 'æ–¹æ³•' in content: score += 1
        if len(content) >= 1200: score += 1
        if 'ã€' in content or '[' in content: score += 0.5  # æœ‰å¼•ç”¨æ ‡æ³¨
        return min(score, 10)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Step 5: ä¿å­˜ + å‘é€å®¡æ ¸é‚®ä»¶ + æ¨è‰ç¨¿
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def send_review_and_push(self, candidates: list, topic_info: dict):
        logger.info("=== Step 5: å®¡æ ¸é‚®ä»¶ + è‰ç¨¿ç®± ===")
        today = datetime.now().strftime('%Y%m%d')

        # ä¿å­˜å€™é€‰æ–‡ä»¶
        output_dir = BASE_DIR / 'output' / today
        output_dir.mkdir(parents=True, exist_ok=True)
        for i, c in enumerate(candidates, 1):
            file_path = output_dir / f'candidate_{i}.md'
            title = c['topic'].replace('"', '').replace("'", '')
            cover = 'https://images.unsplash.com/photo-1677442135703-1787eea5ce01?w=900'
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(f"---\ntitle: {title}\ntype: {c['angle_type']}\nquality_score: {c['quality_score']}\ncover: {cover}\n---\n\n")
                f.write(c['content'])

        # ä¿å­˜åˆ°æ•°æ®åº“
        best = max(candidates, key=lambda x: x['quality_score'])
        article_id = self.db.save_article(
            date=today, topic=best['topic'],
            content=best['content'], candidates=candidates, status='pending_review'
        )
        logger.info(f"âœ… ä¿å­˜æ•°æ®åº“ ID: {article_id}")

        # å‘é€å®¡æ ¸é‚®ä»¶
        smtp = self.secrets['smtp']
        smtp['zapier_email'] = self.secrets['review']['zapier_email']
        mail_sender = ReviewMailSender(smtp)
        mail_sender.send_html_review_email(
            to=self.secrets['review']['recipient'],
            candidates=candidates,
            article_date=today,
            topic_info=topic_info,
            literature=self._current_literature
        )

        # æ¨æœ€é«˜åˆ†å€™é€‰åˆ°è‰ç¨¿ç®±
        best_idx = candidates.index(best) + 1
        best_file = output_dir / f'candidate_{best_idx}.md'
        try:
            result = subprocess.run(
                ['wenyan', 'publish', '-f', str(best_file), '-t', 'lapis', '-h', 'solarized-light'],
                capture_output=True, text=True, timeout=120,
                env={**os.environ, 'WECHAT_APP_ID': self.secrets['wechat']['app_id'], 'WECHAT_APP_SECRET': self.secrets['wechat']['app_secret']}
            )
            if 'ä¸Šä¼ æˆåŠŸ' in result.stdout or 'media_id' in result.stdout:
                logger.info(f"âœ… å€™é€‰ {best_idx}ã€Œ{best['topic']}ã€å·²æ¨é€åˆ°è‰ç¨¿ç®±")
            else:
                logger.warning(f"âš ï¸ è‰ç¨¿ç®±æ¨é€å¤±è´¥: {result.stderr[:200]}")
        except Exception as e:
            logger.warning(f"âš ï¸ è‰ç¨¿ç®±æ¨é€å¼‚å¸¸: {e}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ä¸»å…¥å£
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def run(self, manual_topic: str = None):
        logger.info("ğŸš€ å¯åŠ¨å†…å®¹ç”Ÿäº§ç®¡çº¿ v3.0")
        try:
            topic_info = self.determine_topic(manual_topic)
            literature = self.collect_literature(topic_info)
            if not literature:
                logger.error("æ–‡çŒ®é‡‡é›†å¤±è´¥ï¼Œç»ˆæ­¢")
                return False
            self._current_literature = literature
            topic_designs = self.design_topics(topic_info, literature)
            if not topic_designs:
                logger.error("é€‰é¢˜è®¾è®¡å¤±è´¥ï¼Œç»ˆæ­¢")
                return False
            candidates = self.generate_articles(topic_designs)
            self.send_review_and_push(candidates, topic_info)
            logger.info("âœ… ç®¡çº¿å®Œæˆ")
            return True
        except Exception as e:
            logger.error(f"âŒ ç®¡çº¿å¤±è´¥: {e}", exc_info=True)
            return False


if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--topic', type=str, help='æ‰‹åŠ¨æŒ‡å®šä¸»é¢˜')
    args = parser.parse_args()
    pipeline = ContentPipelineV3()
    success = pipeline.run(manual_topic=args.topic)
    sys.exit(0 if success else 1)
